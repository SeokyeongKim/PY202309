{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20208af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no similar sentence.\n"
     ]
    }
   ],
   "source": [
    "import operator \n",
    "\n",
    "# 1. Preprocess function\n",
    "def preprocess(sentence):\n",
    "    # Convert the sentence to lowercase, split it into words, and create a set of words\n",
    "    return set(sentence.strip().lower().split(\" \"))   \n",
    "\n",
    "# 2. Indexing function\n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs = []\n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines() # Read the lines from a file with UTF-8 encoding\n",
    "    for line in lines:  # Preprocess each line and append the token\n",
    "        tokens = preprocess(line)\n",
    "        file_tokens_pairs.append(tokens)\n",
    "        #print(tokens)\n",
    "    return file_tokens_pairs \n",
    "\n",
    "# 3. Calculate similarity function\n",
    "def calc_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    score_dict = {}  # Initialize a dictionary to store similarity scores\n",
    "    query_token_set = set(preprocessed_query) # Convert the preprocessed query into a set of tokens\n",
    "\n",
    "    for i, sentence_tokens in enumerate(preprocessed_sentences):\n",
    "        all_tokens = query_token_set | sentence_tokens  # Union of query tokens and sentence tokens\n",
    "        same_tokens = query_token_set & sentence_tokens  # Intersection of query tokens and sentence tokens\n",
    "        similarity = len(same_tokens) / len(all_tokens)  # Calculate similarity\n",
    "        score_dict[i] = similarity  # Store the similarity score\n",
    "    #print(score_dict)\n",
    "\n",
    "    return score_dict  \n",
    "\n",
    "# 1. Indexing\n",
    "file_name = \"jhe-koen-dev.en\" \n",
    "file_tokens_pairs = indexing(file_name)  # Index the file and store tokenized lines in a list\n",
    "\n",
    "# 2. Input the query\n",
    "query = input(\"영어 쿼리를 입력하세요 : \")  \n",
    "preprocessed_query = preprocess(query)  # Preprocess the query\n",
    "#print(preprocessed_query)\n",
    "\n",
    "# 3. Calculate similarities based on the same token set\n",
    "score_dict = calc_similarity(preprocessed_query, file_tokens_pairs)  # Calculate similarities with the query\n",
    "\n",
    "# 4. Sort the similarity list\n",
    "sorted_score_list = sorted(score_dict.items(), key=operator.itemgetter(1), reverse=True) # Sort the similarity scores\n",
    "\n",
    "# 5. Print the result\n",
    "if sorted_score_list[0][1] == 0.0: # If the top similarity score is 0, print \"no similar sentences\"\n",
    "    print(\"There is no similar sentence.\")  \n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep=\"\\t\") # Print the header of result table\n",
    "    rank = 1  # Initialize the rank counter\n",
    "    for i, score in sorted_score_list[:10]: # Print the top 10 similar sentences\n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep=\"\\t\")  \n",
    "        rank += 1  # Increment the rank counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044abde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c85abbf3fe96ea8d263374b2ce1ffe851e2aa65d51a6f06c7260e0a203315a09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
