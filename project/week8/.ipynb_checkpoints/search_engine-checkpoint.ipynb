{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20208af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 쿼리를 입력하세요 : Hello My name is Misoo Kim\n",
      "rank\tIndex\tscore\tsentence\n",
      "1\t679\t0.42857142857142855\tmy name is mike.\n",
      "2\t526\t0.25\tmy is bob brother.\n",
      "3\t538\t0.25\tmy hobby traveling. is\n",
      "4\t453\t0.2222222222222222\tsketching mother them. is my\n",
      "5\t241\t0.2\tfather running is my with so-ra.\n",
      "6\t336\t0.2\tat is my family the park.\n",
      "7\t212\t0.18181818181818182\tsister waiting betty for is my me.\n",
      "8\t505\t0.16666666666666666\tsister annie years little old. five is my\n",
      "9\t610\t0.14285714285714285\tyell, would i ready!\" is voice my and raise \"lunch\n",
      "10\t190\t0.125\tsunday. is it\n"
     ]
    }
   ],
   "source": [
    "import operator \n",
    "\n",
    "# 1. Preprocess function\n",
    "def preprocess(sentence):\n",
    "    # Convert the sentence to lowercase, split it into words, and create a set of words.\n",
    "    return set(sentence.strip().lower().split(\" \"))   \n",
    "\n",
    "# 2. Indexing function\n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs = []\n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines()  # Read the lines from a file\n",
    "    for line in lines:\n",
    "        tokens = preprocess(line)\n",
    "        file_tokens_pairs.append(tokens)\n",
    "        #print(tokens)\n",
    "    return file_tokens_pairs \n",
    "\n",
    "# 3. Calculate similarity function\n",
    "def calc_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    score_dict = {}  \n",
    "    query_token_set = set(preprocessed_query)  \n",
    "\n",
    "    for i, sentence_tokens in enumerate(preprocessed_sentences):\n",
    "        all_tokens = query_token_set | sentence_tokens  # Union of query tokens and sentence tokens.\n",
    "        same_tokens = query_token_set & sentence_tokens  # Intersection of query tokens and sentence tokens.\n",
    "        similarity = len(same_tokens) / len(all_tokens)  # Calculate similarity\n",
    "        score_dict[i] = similarity  # Store the similarity score\n",
    "    #print(score_dict)\n",
    "\n",
    "    return score_dict  \n",
    "\n",
    "# 1. Indexing\n",
    "file_name = \"jhe-koen-dev.en\" \n",
    "file_tokens_pairs = indexing(file_name)  \n",
    "\n",
    "# 2. Input the query\n",
    "query = input(\"영어 쿼리를 입력하세요 : \")  \n",
    "preprocessed_query = preprocess(query)  \n",
    "#print(preprocessed_query)\n",
    "\n",
    "# 3. Calculate similarities based on the same token set\n",
    "score_dict = calc_similarity(preprocessed_query, file_tokens_pairs)  \n",
    "\n",
    "# 4. Sort the similarity list\n",
    "sorted_score_list = sorted(score_dict.items(), key=operator.itemgetter(1), reverse=True) \n",
    "\n",
    "# 5. Print the result\n",
    "if sorted_score_list[0][1] == 0.0:\n",
    "    print(\"There is no similar sentence.\")  \n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep=\"\\t\")\n",
    "    rank = 1  \n",
    "    for i, score in sorted_score_list[:10]: \n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep=\"\\t\") \n",
    "        rank += 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044abde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
